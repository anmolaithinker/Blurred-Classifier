{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from imutils import paths\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using OpenCV\n",
    "\n",
    "#### Using Laplacian\n",
    "- the goal of this operators is to measure the\n",
    " amount of edges present in images, through the\n",
    " second derivative or Laplacian\n",
    " \n",
    "- You simply take a single channel of an image (presumably grayscale) and convolve it with the following 3 x 3     kernel \n",
    "\n",
    "- And then take the variance (i.e. standard deviation squared) of the response.\n",
    "\n",
    "- If the variance falls below a pre-defined threshold, then the image is considered blurry; otherwise, the image is not blurry.\n",
    "\n",
    "- To find Predefined Threshold I am checking what is the best threshold by trying various thresholds and analyzing them. You can find the details below\n",
    "##### Refrence - https://www.pyimagesearch.com/2015/09/07/blur-detection-with-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing The Image Size (Making all Images of Same Size)\n",
    "def fix_image_size(image, expected_pixels=2E6):\n",
    "    ratio = float(expected_pixels) / float(image.shape[0] * image.shape[1])\n",
    "    return cv2.resize(image, (0, 0), fx=ratio, fy=ratio)\n",
    "\n",
    "# Estimating Blurr With Laplacian\n",
    "def estimate_blur(image, threshold=200):\n",
    "    if image.ndim == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    blur_map = cv2.Laplacian(image, cv2.CV_64F)\n",
    "    score = np.var(blur_map)\n",
    "    return blur_map, score, bool(score < threshold)\n",
    "\n",
    "# Function to tell whether the image is blur or not\n",
    "def Process(image,threshold):\n",
    "    image = cv2.imread(image)\n",
    "    image = fix_image_size(image)\n",
    "    blurmap,score,b = estimate_blur(image,threshold)\n",
    "#     print('Score : ' + str(score))\n",
    "#     print('Blur : ' + str(b))\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naturally-Blurred\n",
      "Done : Naturally-Blurred\n",
      "Artificially-Blurred\n",
      "Done : Artificially-Blurred\n",
      "NewDigitalBlur\n",
      "Done : NewDigitalBlur\n",
      "Undistorted\n",
      "Done : Undistorted\n"
     ]
    }
   ],
   "source": [
    "Training_file = './TrainingSet/'\n",
    "Images = []\n",
    "filenames = []\n",
    "for filename in os.listdir(Training_file):\n",
    "    lis = []\n",
    "    print(filename)\n",
    "    filenames.append(filename)\n",
    "    for image in os.listdir(Training_file+filename):\n",
    "        lis.append(Training_file+filename+'/'+image)\n",
    "    Images.append(lis)\n",
    "    print('Done : ' + str(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Naturally-Blurred', 'Artificially-Blurred', 'NewDigitalBlur', 'Undistorted']"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "File Name : Naturally-Blurred\n",
      "ThreshHold : 100\n",
      "\n",
      "\n",
      "Count : 69\n",
      "Total : 220\n",
      "Accuracy : 31\n",
      "------------------------\n",
      "File Name : Artificially-Blurred\n",
      "ThreshHold : 100\n",
      "\n",
      "\n",
      "Count : 132\n",
      "Total : 150\n",
      "Accuracy : 88\n",
      "------------------------\n",
      "File Name : NewDigitalBlur\n",
      "ThreshHold : 100\n",
      "\n",
      "\n",
      "Count : 87\n",
      "Total : 150\n",
      "Accuracy : 57\n",
      "------------------>Overall Accuracy<--------------- : 55\n",
      "------------------------\n",
      "File Name : Naturally-Blurred\n",
      "ThreshHold : 300\n",
      "\n",
      "\n",
      "Count : 132\n",
      "Total : 220\n",
      "Accuracy : 60\n",
      "------------------------\n",
      "File Name : Artificially-Blurred\n",
      "ThreshHold : 300\n",
      "\n",
      "\n",
      "Count : 148\n",
      "Total : 150\n",
      "Accuracy : 98\n",
      "------------------------\n",
      "File Name : NewDigitalBlur\n",
      "ThreshHold : 300\n",
      "\n",
      "\n",
      "Count : 139\n",
      "Total : 150\n",
      "Accuracy : 92\n",
      "------------------>Overall Accuracy<--------------- : 80\n",
      "------------------------\n",
      "File Name : Naturally-Blurred\n",
      "ThreshHold : 500\n",
      "\n",
      "\n",
      "Count : 171\n",
      "Total : 220\n",
      "Accuracy : 77\n",
      "------------------------\n",
      "File Name : Artificially-Blurred\n",
      "ThreshHold : 500\n",
      "\n",
      "\n",
      "Count : 150\n",
      "Total : 150\n",
      "Accuracy : 100\n",
      "------------------------\n",
      "File Name : NewDigitalBlur\n",
      "ThreshHold : 500\n",
      "\n",
      "\n",
      "Count : 148\n",
      "Total : 150\n",
      "Accuracy : 98\n",
      "------------------>Overall Accuracy<--------------- : 90\n",
      "------------------------\n",
      "File Name : Naturally-Blurred\n",
      "ThreshHold : 700\n",
      "\n",
      "\n",
      "Count : 193\n",
      "Total : 220\n",
      "Accuracy : 87\n",
      "------------------------\n",
      "File Name : Artificially-Blurred\n",
      "ThreshHold : 700\n",
      "\n",
      "\n",
      "Count : 150\n",
      "Total : 150\n",
      "Accuracy : 100\n",
      "------------------------\n",
      "File Name : NewDigitalBlur\n",
      "ThreshHold : 700\n",
      "\n",
      "\n",
      "Count : 148\n",
      "Total : 150\n",
      "Accuracy : 98\n",
      "------------------>Overall Accuracy<--------------- : 94\n",
      "------------------------\n",
      "File Name : Naturally-Blurred\n",
      "ThreshHold : 900\n",
      "\n",
      "\n",
      "Count : 197\n",
      "Total : 220\n",
      "Accuracy : 89\n",
      "------------------------\n",
      "File Name : Artificially-Blurred\n",
      "ThreshHold : 900\n",
      "\n",
      "\n",
      "Count : 150\n",
      "Total : 150\n",
      "Accuracy : 100\n",
      "------------------------\n",
      "File Name : NewDigitalBlur\n",
      "ThreshHold : 900\n",
      "\n",
      "\n",
      "Count : 150\n",
      "Total : 150\n",
      "Accuracy : 100\n",
      "------------------>Overall Accuracy<--------------- : 95\n",
      "------------------------\n",
      "File Name : Naturally-Blurred\n",
      "ThreshHold : 1100\n",
      "\n",
      "\n",
      "Count : 208\n",
      "Total : 220\n",
      "Accuracy : 94\n",
      "------------------------\n",
      "File Name : Artificially-Blurred\n",
      "ThreshHold : 1100\n",
      "\n",
      "\n",
      "Count : 150\n",
      "Total : 150\n",
      "Accuracy : 100\n",
      "------------------------\n",
      "File Name : NewDigitalBlur\n",
      "ThreshHold : 1100\n",
      "\n",
      "\n",
      "Count : 150\n",
      "Total : 150\n",
      "Accuracy : 100\n",
      "------------------>Overall Accuracy<--------------- : 97\n"
     ]
    }
   ],
   "source": [
    "accuracies = [] # List to store accuracies(Overall Accuracy)\n",
    "thresholds = []  # List to store thresholds\n",
    "threshold = 100 # Initial Threshhold\n",
    "\n",
    "while threshold < 1200: # Loop until threshhold < 1200\n",
    "    \n",
    "    total = len(Images[0]) + len(Images[1]) + len(Images[2]) # Total number of Images\n",
    "    total_Count = 0  # Initializing Total Count = 0 (Variable which will tell how much predictions are correct)\n",
    "    for i in range(0,3): # Loop (0,1,2,3)\n",
    "        print('------------------------')\n",
    "        print 'File Name : ' + filenames[i]\n",
    "        print('ThreshHold : ' + str(threshold))\n",
    "        print '\\n'\n",
    "        count = 0\n",
    "        Total = len(Images[i])\n",
    "        for i in Images[i]:\n",
    "            b = Process(i,threshold) # Calling Process Function Which will tell whether the image is blur or not\n",
    "            if b: # if b is true\n",
    "                count = count + 1  # increment the counter\n",
    "        total_Count = total_Count + count\n",
    "        print('Count : ' + str(count))\n",
    "        print('Total : ' + str(Total))\n",
    "        acc = int((float(count)/float(Total))*100) # Accuracy of prediction corresponding to one folder\n",
    "        print ('Accuracy : ' + str(acc))            \n",
    "    Overral_Acu = int((float(total_Count)/float(total))*100) # Calculating Overall Accuracy\n",
    "    accuracies.append(Overral_Acu) # Appending accuracy(Overall)\n",
    "    thresholds.append(threshold) # Appending Threshold\n",
    "    print('------------------>Overall Accuracy<--------------- : ' + str(Overral_Acu))    \n",
    "    threshold = threshold + 200 # incrementing threshold by 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold : 100 --> Accuracy : 55\n",
      "Threshold : 300 --> Accuracy : 80\n",
      "Threshold : 500 --> Accuracy : 90\n",
      "Threshold : 700 --> Accuracy : 94\n",
      "Threshold : 900 --> Accuracy : 95\n",
      "Threshold : 1100 --> Accuracy : 97\n"
     ]
    }
   ],
   "source": [
    "# Checking Overall Accuracy with corresponding threshold\n",
    "\n",
    "for i in range(0,6):\n",
    "    print ('Threshold : ' + str(thresholds[i]) + ' --> Accuracy : ' + str(accuracies[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f59449ba1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Overall Accuracy\n",
    "\n",
    "y = accuracies\n",
    "x = thresholds\n",
    "plt.plot(x,y)\n",
    "plt.xlabel('Thresholds')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Threshold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DigitalBlurSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalpath = './EvaluationSet'\n",
    "DBS = pd.read_excel(evalpath + '/DigitalBlurSet.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MyDigital Blur</th>\n",
       "      <th>Blur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DiskR10_1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DiskR10_10.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DiskR10_11.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DiskR10_12.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DiskR10_13.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MyDigital Blur  Blur\n",
       "0   DiskR10_1.jpg      1\n",
       "1  DiskR10_10.jpg      1\n",
       "2  DiskR10_11.jpg      1\n",
       "3  DiskR10_12.jpg      1\n",
       "4  DiskR10_13.jpg      1"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DBS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "DigitalBlurSet = evalpath + '/DigitalBlurSet/'\n",
    "Total = len(DBS['MyDigital Blur'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ---->\n",
      "Accuracy : 93\n"
     ]
    }
   ],
   "source": [
    "## Getting Accuracy\n",
    "\n",
    "count = 0\n",
    "print ('Starting ---->')\n",
    "for i in range(0,len(DBS['MyDigital Blur'])):\n",
    "    filename = DBS['MyDigital Blur'][i]\n",
    "    filepath = DigitalBlurSet + (filename.strip())\n",
    "    b = Process(filepath, 700)\n",
    "    if int(b)==DBS['Blur'][i]:\n",
    "        count = count+1    \n",
    "print('Accuracy : ' + str(int((float(count)/float(Total))*100)))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NaturalBlurSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalpath = './EvaluationSet'\n",
    "NBS = pd.read_excel(evalpath + '/NaturalBlurSet.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Name</th>\n",
       "      <th>Blur Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Original_1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Original_2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Original_3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Original_4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Original_5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Image Name  Blur Label\n",
       "0  Original_1          -1\n",
       "1  Original_2          -1\n",
       "2  Original_3          -1\n",
       "3  Original_4           1\n",
       "4  Original_5           1"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaturalBlurSet = evalpath + '/NaturalBlurSet/'\n",
    "Total = len(NBS['Image Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ---->\n",
      "Accuracy : 41\n"
     ]
    }
   ],
   "source": [
    "## Getting Accuracy\n",
    "\n",
    "count = 0\n",
    "print ('Starting ---->')\n",
    "for i in range(0,Total):\n",
    "    filename = NBS['Image Name'][i]\n",
    "    filepath = NaturalBlurSet + (filename.strip()) + '.jpg'\n",
    "    b = Process(filepath, 700)\n",
    "    if int(b)==NBS['Blur Label'][i]:\n",
    "        count = count+1    \n",
    "print('Accuracy : ' + str(int((float(count)/float(Total))*100)))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using CNN\n",
    "\n",
    "- Model Used -> LENET\n",
    "- Batch Size -> 32\n",
    "- Epochs -> 5 \n",
    "\n",
    "### Process : \n",
    "\n",
    "- Making of a Training and Testing Dataset for\n",
    " - Naturally Blurred Dataset and undistorted\n",
    " - Digitally Blurred Dataset and undistorted\n",
    " - Combining All Blurred and undistorted <br/>\n",
    "<br>\n",
    "- Making of LENET Model<br>\n",
    "<br>\n",
    "- Compiling The Model<br>\n",
    "<br>\n",
    "- Making Of DataAugmented Data for Improving Accuracy<br>\n",
    "<br>\n",
    "- Training The Model<br>\n",
    "<br>\n",
    "- Evalutaiong The Model on Evalutaion Set <br/>\n",
    "<br>\n",
    "- To Improve Accuracy Further :\n",
    " - Try on Differet Models -> VGG16, Inception   \n",
    " - Increase The number of Epochs\n",
    " - More Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import pylab\n",
    "import imageio\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.core import Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First : Naturally Blurred VS Undistorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naturally-Blurred\n",
      "Done : Naturally-Blurred\n",
      "Artificially-Blurred\n",
      "Done : Artificially-Blurred\n",
      "CNN-Natural-Train\n",
      "Done : CNN-Natural-Train\n",
      "NewDigitalBlur\n",
      "Done : NewDigitalBlur\n",
      "CNN-Natural-Test\n",
      "Done : CNN-Natural-Test\n",
      "Undistorted\n",
      "Done : Undistorted\n"
     ]
    }
   ],
   "source": [
    "# Making of Train and test Dataset\n",
    "Training_file = './TrainingSet/'\n",
    " \n",
    "Images = [] # Array for storing all folders images\n",
    "filenames = [] # Array to store all folders name\n",
    "\n",
    "for filename in os.listdir(Training_file): # Looping through Folders and getting file name one by one\n",
    "    lis = []         # Temporary List to store path of one image inside one folder\n",
    "    print(filename)\n",
    "    filenames.append(filename) # Appending File name\n",
    "    for image in os.listdir(Training_file+filename): # Getting Images from one folder \n",
    "        lis.append(Training_file+filename+'/'+image) # Appending image path to temporary list\n",
    "    Images.append(lis)              # Appending Temporary List to the Image array\n",
    "    print('Done : ' + str(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "630"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Images[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------->Start\n",
      "----------->Done\n"
     ]
    }
   ],
   "source": [
    "# Making of Naturally Blurred CNN Dataset\n",
    "\n",
    "#   -> Making 2 folders CNN-Train-Natural and CNN-Test-Natural\n",
    "#   -> Making 2 folders inside each folder named Naturally-Blurred and undistorted\n",
    "#   -> Splitting the data in the ration of 80% (Train) and 20%(Test) in each Naturally Blurred and undistorted\n",
    "\n",
    "Training_file = './CNNTraining/'\n",
    "if not os.path.exists(Training_file):\n",
    "    os.makedirs(Training_file)   \n",
    "def MakeNeutralDataset():\n",
    "    CNNTrain = 'CNN-Train-Natural/'\n",
    "    CNNTest = 'CNN-Test-Neutral/'\n",
    "    direc =  Training_file + CNNTrain\n",
    "    if not os.path.exists(direc):\n",
    "        os.makedirs(direc)    \n",
    "    direc =  Training_file + CNNTest\n",
    "    if not os.path.exists(direc):\n",
    "        os.makedirs(direc)    \n",
    "    direc =  Training_file + CNNTrain + 'Naturally-Blurred'\n",
    "    if not os.path.exists(direc):\n",
    "        os.makedirs(direc)    \n",
    "    direc =  Training_file + CNNTrain + 'undistorted'\n",
    "    if not os.path.exists(direc):\n",
    "        os.makedirs(direc)    \n",
    "    direc =  Training_file + CNNTest + 'undistorted'\n",
    "    if not os.path.exists(direc):\n",
    "        os.makedirs(direc)    \n",
    "    direc =  Training_file + CNNTest + 'Naturally-Blurred'\n",
    "    if not os.path.exists(direc):\n",
    "        os.makedirs(direc)    \n",
    "\n",
    "    print('----------->Start')\n",
    "    for i in range(0,len(Images[0])):\n",
    "        # Putting into Train 80%\n",
    "        if i<(len(Images[0]) * 0.8):\n",
    "            source = Images[0][i]\n",
    "            dest = Training_file+CNNTrain+'Naturally-Blurred/'+str(i)+'.jpg'\n",
    "            shutil.copy(source,dest)\n",
    "        else:\n",
    "            source = Images[0][i]\n",
    "            dest = Training_file+CNNTest+'Naturally-Blurred/'+str(i)+'.jpg'\n",
    "            shutil.copy(source,dest)\n",
    "        \n",
    "    print('----------->Done')  \n",
    "    print('----------->Start')\n",
    "    for i in range(0,len(Images[3])):\n",
    "        # Putting into Train 80%\n",
    "        if i<(len(Images[3]) * 0.8):\n",
    "            source = Images[3][i]\n",
    "            dest = Training_file+CNNTrain+'undistorted/'+str(i)+'.jpg'\n",
    "            shutil.copy(source,dest)\n",
    "        else:\n",
    "            source = Images[3][i]\n",
    "            dest = Training_file+CNNTest+'undistorted/'+str(i)+'.jpg'\n",
    "            shutil.copy(source,dest)\n",
    "        \n",
    "    print('----------->Done')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------->Start\n",
      "----------->Done\n"
     ]
    }
   ],
   "source": [
    "MakeNeutralDataset()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 64, 64, 20)        1520      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 64, 64, 20)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 32, 32, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 32, 32, 50)        25050     \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 32, 32, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 16, 16, 50)        0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 500)               6400500   \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 1002      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 6,428,072\n",
      "Trainable params: 6,428,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LENET Model\n",
    "# Conv -> MaxPool -> Conv -> MaxPool -> Flatten -> FC -> FC\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(20, (5, 5), padding=\"same\",input_shape=(64, 64, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500))\n",
    "model.add(Activation(\"relu\")) \n",
    "model.add(Dense(2))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 680 images belonging to 2 classes.\n",
      "Found 170 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Making training set and testing set\n",
    "# Image Data Generator is used for Data Augmentation\n",
    "\n",
    "Training_file = './CNNTraining'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(Training_file+'/CNN-Train-Natural',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(Training_file+'/CNN-Test-Neutral/',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(680/32) # Steps per Epoch\n",
    "print(170/32) # Validation Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "21/21 [==============================] - 117s 6s/step - loss: 2.3426 - acc: 0.7006 - val_loss: 0.5900 - val_acc: 0.7562\n",
      "Epoch 2/5\n",
      "21/21 [==============================] - 134s 6s/step - loss: 0.5667 - acc: 0.7368 - val_loss: 0.6004 - val_acc: 0.6957\n",
      "Epoch 3/5\n",
      "21/21 [==============================] - 126s 6s/step - loss: 0.4991 - acc: 0.7604 - val_loss: 0.4469 - val_acc: 0.7971\n",
      "Epoch 4/5\n",
      "21/21 [==============================] - 106s 5s/step - loss: 0.5244 - acc: 0.7647 - val_loss: 0.5468 - val_acc: 0.7609\n",
      "Epoch 5/5\n",
      "21/21 [==============================] - 145s 7s/step - loss: 0.4600 - acc: 0.7991 - val_loss: 0.5074 - val_acc: 0.7319\n"
     ]
    }
   ],
   "source": [
    "#Training Model\n",
    "model.fit_generator(training_set,\n",
    "                         steps_per_epoch = 21,\n",
    "                         epochs = 5,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 5)\n",
    "                         \n",
    "model.save('modelLenet2.h5') # Saving Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Model\n",
    "model  = load_model('modelLenet2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Prediction\n",
    "\n",
    "# -> Reading the image from opencv\n",
    "# -> Resizing into (64,64)\n",
    "# -> Rescaling\n",
    "# -> Converting into Array\n",
    "# -> Expanding dimensions\n",
    "# -> Getting the result of prediction and index of class\n",
    "def predict(image):\n",
    "    # load the image, pre-process it, and store it in the data list\n",
    "    image = cv2.imread(image)\n",
    "    image = cv2.resize(image, (64, 64))\n",
    "    image = image.astype(\"float\") / 255.0\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    result = model.predict(image)[0]\n",
    "    idx = np.argmax(result)\n",
    "    if(idx == 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Naturally-Blurred': 0, 'undistorted': 1}"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking which index belongs to which class\n",
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "\n",
    "evalpath = './EvaluationSet'\n",
    "NBS = pd.read_excel(evalpath + '/NaturalBlurSet.xlsx')\n",
    "NaturalBlurSet = evalpath + '/NaturalBlurSet/'\n",
    "Total = len(NBS['Image Name']) # Total number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ---->\n",
      "Accuracy : 61\n"
     ]
    }
   ],
   "source": [
    "# Getting the Accuracy\n",
    "count = 0\n",
    "print ('Starting ---->')\n",
    "for i in range(0,Total):\n",
    "    filename = NBS['Image Name'][i]\n",
    "    filepath = NaturalBlurSet + (filename.strip()) + '.jpg'\n",
    "    b = predict(filepath)\n",
    "    if b==NBS['Blur Label'][i]:\n",
    "        count = count+1    \n",
    "print('Accuracy : ' + str(int((float(count)/float(Total))*100)))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digitally Blurred Vs Undistorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making of Digitally Blurred CNN Dataset\n",
    "\n",
    "#   -> Making 2 folders CNN-Train-Digital and CNN-Test-Digital\n",
    "#   -> Making 2 folders inside each folder named Digital-Blurred and undistorted\n",
    "#   -> Splitting the data in the ration of 80% (Train) and 20%(Test) in each Digital Blurred and undistorted\n",
    "\n",
    "Training_file = './CNNTraining/'\n",
    "if not os.path.exists(Training_file):\n",
    "    os.makedirs(Training_file)   \n",
    "def MakeDigitalDataset():\n",
    "    CNNTrain = 'CNN-Train-Digital/'\n",
    "    CNNTest = 'CNN-Test-Digital/'\n",
    "    direc =  Training_file + CNNTrain\n",
    "    if not os.path.exists(direc):\n",
    "        os.makedirs(direc)    \n",
    "    direc =  Training_file + CNNTest\n",
    "    if not os.path.exists(direc):\n",
    "        os.makedirs(direc)    \n",
    "    direc =  Training_file + CNNTrain + 'Digital-Blurred'\n",
    "    if not os.path.exists(direc):\n",
    "        os.makedirs(direc)    \n",
    "    direc =  Training_file + CNNTrain + 'undistorted'\n",
    "    if not os.path.exists(direc):\n",
    "        os.makedirs(direc)    \n",
    "    direc =  Training_file + CNNTest + 'undistorted'\n",
    "    if not os.path.exists(direc):\n",
    "        os.makedirs(direc)    \n",
    "    direc =  Training_file + CNNTest + 'Digital-Blurred'\n",
    "    if not os.path.exists(direc):\n",
    "        os.makedirs(direc)    \n",
    "\n",
    "    print('----------->Start')\n",
    "    for i in range(0,len(Images[0])):\n",
    "        # Putting into Train 80%\n",
    "        if i<(len(Images[1]) * 0.8):\n",
    "            source = Images[0][i]\n",
    "            dest = Training_file+CNNTrain+'Digital-Blurred/'+str(i)+'.jpg'\n",
    "            shutil.copy(source,dest)\n",
    "        else:\n",
    "            source = Images[0][i]\n",
    "            dest = Training_file+CNNTest+'Digital-Blurred/'+str(i)+'.jpg'\n",
    "            shutil.copy(source,dest)\n",
    "        \n",
    "    print('----------->Done')  \n",
    "    print('----------->Start')\n",
    "    for i in range(0,len(Images[5])):\n",
    "        # Putting into Train 80%\n",
    "        if i<(len(Images[5]) * 0.8):\n",
    "            source = Images[5][i]\n",
    "            dest = Training_file+CNNTrain+'undistorted/'+str(i)+'.jpg'\n",
    "            shutil.copy(source,dest)\n",
    "        else:\n",
    "            source = Images[5][i]\n",
    "            dest = Training_file+CNNTest+'undistorted/'+str(i)+'.jpg'\n",
    "            shutil.copy(source,dest)\n",
    "        \n",
    "    print('----------->Done')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------->Start\n",
      "----------->Done\n",
      "----------->Start\n",
      "----------->Done\n"
     ]
    }
   ],
   "source": [
    "MakeDigitalDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 64, 64, 20)        1520      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 64, 64, 20)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 32, 32, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 32, 32, 50)        25050     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 32, 32, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 16, 16, 50)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 500)               6400500   \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 1002      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 6,428,072\n",
      "Trainable params: 6,428,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Same LENET Model as Above\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(20, (5, 5), padding=\"same\",input_shape=(64, 64, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500))\n",
    "model.add(Activation(\"relu\")) \n",
    "model.add(Dense(2))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n",
      "Found 226 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Making training set and testing set\n",
    "# Image Data Generator is used for Data Augmentation\n",
    "\n",
    "Training_file = './CNNTraining'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(Training_file + '/CNN-Train-Digital',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(Training_file + '/CNN-Test-Digital/',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(624/32) # Steps per Epoch\n",
    "print (226/32) # Validation Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "19/19 [==============================] - 114s 6s/step - loss: 0.3403 - acc: 0.8702 - val_loss: 0.7463 - val_acc: 0.6429\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 131s 7s/step - loss: 0.3194 - acc: 0.8848 - val_loss: 0.6643 - val_acc: 0.6495\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 122s 6s/step - loss: 0.2380 - acc: 0.9128 - val_loss: 0.9406 - val_acc: 0.6753\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 115s 6s/step - loss: 0.2344 - acc: 0.9242 - val_loss: 1.3240 - val_acc: 0.6186\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 113s 6s/step - loss: 0.1518 - acc: 0.9473 - val_loss: 0.9820 - val_acc: 0.5722\n"
     ]
    }
   ],
   "source": [
    "#Training Model\n",
    "model.fit_generator(training_set,\n",
    "                         steps_per_epoch = 19,\n",
    "                         epochs = 5,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 7)\n",
    "                         \n",
    "model.save('modelLenetDigital.h5') # Saving The Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "    # load the image, pre-process it, and store it in the data list\n",
    "    image = cv2.imread(image)\n",
    "    image = cv2.resize(image, (64, 64))\n",
    "    image = image.astype(\"float\") / 255.0\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    result = model.predict(image)[0]\n",
    "    idx = np.argmax(result)\n",
    "    if(idx == 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Digital-Blurred': 0, 'undistorted': 1}"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting idx corresponding to classes\n",
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the Model\n",
    "evalpath = './EvaluationSet'\n",
    "DBS = pd.read_excel(evalpath + '/DigitalBlurSet.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "DigitalBlurSet = evalpath + '/DigitalBlurSet/'\n",
    "Total = len(DBS['MyDigital Blur']) # Total Number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ---->\n",
      "Accuracy : 18\n"
     ]
    }
   ],
   "source": [
    "# Getting The Accuracy\n",
    "\n",
    "count = 0\n",
    "print ('Starting ---->')\n",
    "for i in range(0,Total):\n",
    "    filename = DBS['MyDigital Blur'][i]\n",
    "    filepath = DigitalBlurSet + (filename.strip())\n",
    "    b = predict(filepath)\n",
    "    if b==DBS['Blur'][i]:\n",
    "        count = count+1    \n",
    "print('Accuracy : ' + str(int((float(count)/float(Total))*100)))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digitally Blurred + Naturally Blurred VS Undistorted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Naturally-Blurred', 'Artificially-Blurred', 'NewDigitalBlur', 'Undistorted']"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combining all Blurred and undistorted\n",
    "\n",
    "# Making of Digitally Blurred CNN Dataset\n",
    "\n",
    "#   -> Making 2 folders CNN-Train-Digital and CNN-Test-Digital\n",
    "#   -> Making 2 folders inside each folder named Digital-Blurred and undistorted\n",
    "#   -> Splitting the data in the ration of 80% (Train) and 20%(Test) in each Digital Blurred and undistorted\n",
    "\n",
    "Training_file = './CNNTraining/'\n",
    "if not os.path.exists(Training_file):\n",
    "    os.makedirs(Training_file)    \n",
    "def MakeAllDataset():\n",
    "    CNNTrain = 'CNN-Train-All/'\n",
    "    CNNTest = 'CNN-Test-All/'\n",
    "    direc =  Training_file + CNNTrain\n",
    "    if not os.path.exists(direc):\n",
    "        os.makedirs(direc)    \n",
    "    direc =  Training_file + CNNTest\n",
    "    if not os.path.exists(direc):\n",
    "        os.makedirs(direc)    \n",
    "    direc =  Training_file + CNNTrain + 'Blurred'\n",
    "    if not os.path.exists(direc):\n",
    "        os.makedirs(direc)    \n",
    "    direc =  Training_file + CNNTrain + 'undistorted'\n",
    "    if not os.path.exists(direc):\n",
    "        os.makedirs(direc)    \n",
    "    direc =  Training_file + CNNTest + 'undistorted'\n",
    "    if not os.path.exists(direc):\n",
    "        os.makedirs(direc)    \n",
    "    direc =  Training_file + CNNTest + 'Blurred'\n",
    "    if not os.path.exists(direc):\n",
    "        os.makedirs(direc)    \n",
    "\n",
    "    print('----------->Start')\n",
    "    for i in range(0,len(Images[0])):\n",
    "        # Putting into Train 80%\n",
    "        if i<(len(Images[0]) * 0.8):\n",
    "            source = Images[0][i]\n",
    "            dest = Training_file+CNNTrain+'Blurred/'+str(i)+'.jpg'\n",
    "            shutil.copy(source,dest)            \n",
    "        else:\n",
    "            source = Images[0][i]\n",
    "            dest = Training_file+CNNTest+'Blurred/'+str(i)+'.jpg'\n",
    "            shutil.copy(source,dest)\n",
    "            \n",
    "    for i in range(0,len(Images[1])):\n",
    "        # Putting into Train 80%\n",
    "        if i<(len(Images[1]) * 0.8):\n",
    "            source = Images[1][i]\n",
    "            dest = Training_file+CNNTrain+'Blurred/'+str(i)+'.jpg'\n",
    "            shutil.copy(source,dest)\n",
    "            \n",
    "        else:\n",
    "            source = Images[1][i]\n",
    "            dest = Training_file+CNNTest+'Blurred/'+str(i)+'.jpg'\n",
    "            shutil.copy(source,dest)\n",
    "            \n",
    "            \n",
    "    for i in range(0,len(Images[2])):\n",
    "        # Putting into Train 80%\n",
    "        if i<(len(Images[2]) * 0.8):\n",
    "            source = Images[2][i]\n",
    "            dest = Training_file+CNNTrain+'Blurred/'+str(i)+'.jpg'\n",
    "            shutil.copy(source,dest)\n",
    "            \n",
    "        else:\n",
    "            source = Images[2][i]\n",
    "            dest = Training_file+CNNTest+'Blurred/'+str(i)+'.jpg'\n",
    "            shutil.copy(source,dest)\n",
    "        \n",
    "    print('----------->Done')  \n",
    "    print('----------->Start')\n",
    "    for i in range(0,len(Images[3])):\n",
    "        # Putting into Train 80%\n",
    "        if i<(len(Images[3]) * 0.8):\n",
    "            source = Images[3][i]\n",
    "            dest = Training_file+CNNTrain+'undistorted/'+str(i)+'.jpg'\n",
    "            shutil.copy(source,dest)\n",
    "        else:\n",
    "            source = Images[3][i]\n",
    "            dest = Training_file+CNNTest+'undistorted/'+str(i)+'.jpg'\n",
    "            shutil.copy(source,dest)\n",
    "        \n",
    "    print('----------->Done')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------->Start\n",
      "----------->Done\n",
      "----------->Start\n",
      "----------->Done\n"
     ]
    }
   ],
   "source": [
    "MakeAllDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 64, 64, 20)        1520      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 64, 64, 20)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 32, 32, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 32, 32, 50)        25050     \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 32, 32, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 16, 16, 50)        0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 500)               6400500   \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 2)                 1002      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 6,428,072\n",
      "Trainable params: 6,428,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Same LENET Model as Above\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(20, (5, 5), padding=\"same\",input_shape=(64, 64, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500))\n",
    "model.add(Activation(\"relu\")) \n",
    "model.add(Dense(2))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 680 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Making training set and testing set\n",
    "# Image Data Generator is used for Data Augmentation\n",
    "\n",
    "Training_file = './CNNTraining'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(Training_file + '/CNN-Train-All',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(Training_file + '/CNN-Test-All/',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(680/32) # Steps per Epoch\n",
    "print (200/32) # Validation Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "21/21 [==============================] - 183s 9s/step - loss: 0.6889 - acc: 0.6806 - val_loss: 0.6415 - val_acc: 0.6302\n",
      "Epoch 2/5\n",
      "21/21 [==============================] - 135s 6s/step - loss: 0.5448 - acc: 0.7394 - val_loss: 0.6319 - val_acc: 0.6429\n",
      "Epoch 3/5\n",
      "21/21 [==============================] - 135s 6s/step - loss: 0.5190 - acc: 0.7515 - val_loss: 0.7785 - val_acc: 0.6190\n",
      "Epoch 4/5\n",
      "21/21 [==============================] - 159s 8s/step - loss: 0.4870 - acc: 0.7398 - val_loss: 0.6258 - val_acc: 0.6190\n",
      "Epoch 5/5\n",
      "21/21 [==============================] - 113s 5s/step - loss: 0.4309 - acc: 0.7798 - val_loss: 0.8686 - val_acc: 0.6548\n"
     ]
    }
   ],
   "source": [
    "#Training Model\n",
    "model.fit_generator(training_set,\n",
    "                         steps_per_epoch = 21,\n",
    "                         epochs = 5,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 6)\n",
    "                         \n",
    "model.save('modelLenetAll.h5') # Saving The Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "    # load the image, pre-process it, and store it in the data list\n",
    "    image = cv2.imread(image)\n",
    "    image = cv2.resize(image, (64, 64))\n",
    "    image = image.astype(\"float\") / 255.0\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    result = model.predict(image)[0]\n",
    "    idx = np.argmax(result)\n",
    "    if(idx == 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Blurred': 0, 'undistorted': 1}"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting idx corresponding to classes\n",
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the Model\n",
    "evalpath = './EvaluationSet'\n",
    "DBS = pd.read_excel(evalpath + '/DigitalBlurSet.xlsx')\n",
    "DigitalBlurSet = evalpath + '/DigitalBlurSet/'\n",
    "Total = len(DBS['MyDigital Blur']) # Total Number of rows\n",
    "\n",
    "evalpath = './EvaluationSet'\n",
    "NBS = pd.read_excel(evalpath + '/NaturalBlurSet.xlsx')\n",
    "NaturalBlurSet = evalpath + '/NaturalBlurSet/'\n",
    "Total1 = len(NBS['Image Name']) # Total number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ---->\n",
      "Digitally Blurred Accuracy : 11\n",
      "Starting ---->\n",
      " Naturally BlurredAccuracy : 59\n"
     ]
    }
   ],
   "source": [
    "# Getting The Digitally Blurred Accuracy\n",
    "count = 0\n",
    "print ('Starting ---->')\n",
    "for i in range(0,Total):\n",
    "    filename = DBS['MyDigital Blur'][i]\n",
    "    filepath = DigitalBlurSet + (filename.strip())\n",
    "    b = predict(filepath)\n",
    "    if b==DBS['Blur'][i]:\n",
    "        count = count+1    \n",
    "print('Digitally Blurred Accuracy : ' + str(int((float(count)/float(Total))*100))) \n",
    "\n",
    "# Getting the Naturally Blurred Accuracy\n",
    "count = 0\n",
    "print ('Starting ---->')\n",
    "for i in range(0,Total1):\n",
    "    filename = NBS['Image Name'][i]\n",
    "    filepath = NaturalBlurSet + (filename.strip()) + '.jpg'\n",
    "    b = predict(filepath)\n",
    "    if b==NBS['Blur Label'][i]:\n",
    "        count = count+1    \n",
    "print(' Naturally BlurredAccuracy : ' + str(int((float(count)/float(Total1))*100)))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
